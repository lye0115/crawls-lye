# 网页 Table 数据爬取工具

这个工具专门用于爬取网页中的表格数据，特别适用于需要登录的管理后台页面。现在支持**自动登录**功能，包括滑块验证码的自动处理。

## 功能特点

1. **智能表格检测** - 自动识别和提取网页中的数据表格
2. **自动登录支持** - 自动填写用户名密码，处理滑块验证码
3. **多格式导出** - 同时保存为 JSON 和 CSV 格式
4. **灵活配置** - 可调整表格检测阈值和提取策略
5. **会话保持** - 使用 session 机制，避免浏览器自动关闭
6. **智能验证码处理** - 自动识别和处理滑块验证码

## 安装依赖

```bash
pip install -r requirements.txt
```

## 使用方法

### 1. 基本使用

```bash
python main.py
```

### 2. 程序流程

1. **启动浏览器** - 程序会打开一个浏览器窗口
2. **自动访问登录页面** - 自动导航到目标 URL
3. **自动填写登录信息** - 自动填入预设的用户名和密码
4. **自动处理滑块验证** - 模拟人工滑动操作完成验证
5. **自动点击登录** - 查找并点击登录按钮
6. **等待登录成功** - 智能检测登录是否成功
7. **自动提取表格数据** - 在同一会话中提取页面表格
8. **保存结果** - 数据保存为 JSON 和 CSV 文件

### 3. 输出文件

- `zjrmob_order_daily.json` - 完整的数据结构
- `zjrmob_order_daily_table_1.csv` - 第一个表格的 CSV 格式
- `zjrmob_order_daily_table_2.csv` - 第二个表格的 CSV 格式（如果存在）

## 代码功能说明

### 主要函数

#### `auto_login_and_extract(url, username, password)`

- **功能**: 自动登录并提取指定网页的表格数据
- **参数**:
  - `url`: 目标网页地址
  - `username`: 登录用户名
  - `password`: 登录密码
- **返回**: 包含表格数据和登录状态的字典

#### `save_to_files(data, filename_prefix)`

- **功能**: 将数据保存为不同格式的文件
- **参数**:
  - `data`: 要保存的数据
  - `filename_prefix`: 文件名前缀

### 自动登录机制

#### 智能元素识别

程序会自动查找以下元素：

**用户名输入框**：

- `input[name="username"]`
- `input[name="account"]`
- `input[type="text"]`
- `input[placeholder*="用户名"]`
- 等多种选择器

**密码输入框**：

- `input[name="password"]`
- `input[type="password"]`
- `input[placeholder*="密码"]`
- 等多种选择器

**滑块验证码**：

- `.slider-btn`
- `.slide-button`
- `.captcha-slider`
- 等多种滑块选择器

**登录按钮**：

- `button[type="submit"]`
- 包含"登录"、"登陆"、"提交"文本的按钮
- 等多种按钮选择器

#### 滑块验证处理

- 自动计算滑动距离
- 模拟真实的鼠标拖拽操作
- 分步滑动，添加随机延迟
- 触发完整的鼠标事件序列

#### 登录成功检测

- URL 变化检测
- 用户信息元素检测
- 登出按钮检测
- 页面标题检测
- 表格元素检测

### 配置参数

#### 浏览器配置

```python
browser_config = BrowserConfig(
    headless=False,  # 非无头模式，方便观察过程
    verbose=True,    # 显示详细日志
    user_agent="...", # 模拟真实浏览器
    extra_args=["--no-first-run", "--disable-blink-features=AutomationControlled"]  # 反检测
)
```

#### 登录配置

```python
login_config = CrawlerRunConfig(
    session_id="auto_login_session",  # 会话保持
    js_code=login_js,                 # 登录脚本
    wait_for=wait_for_login_success,  # 等待登录成功
    delay_before_return_html=8,       # 充足的处理时间
    page_timeout=60000                # 60秒超时
)
```

#### 数据提取配置

```python
extract_config = CrawlerRunConfig(
    session_id=session_id,            # 复用会话
    js_only=True,                     # 在同一页面继续
    table_score_threshold=3,          # 降低表格检测阈值
    wait_for="table"                  # 等待表格加载
)
```

## 常见问题

### Q: 自动登录失败怎么办？

A: 如果自动登录失败，程序会自动切换到手动登录模式，你可以在浏览器中手动完成登录，然后按回车继续。

### Q: 滑块验证码识别失败？

A: 程序支持多种滑块选择器，如果识别失败，可能需要检查页面的具体滑块实现。可以手动完成验证。

### Q: 为什么检测不到表格？

A: 可以尝试降低 `table_score_threshold` 参数值，从 3 降到 1 或更低。

### Q: 如何修改登录信息？

A: 在 `main()` 函数中修改 `username` 和 `password` 变量的值。

### Q: 如何处理不同类型的验证码？

A: 目前支持滑块验证码，其他类型的验证码可能需要手动处理。

### Q: 程序运行太慢？

A: 可以减少 `delay_before_return_html` 的值，但要确保页面有足够时间加载。

## 自定义配置

如果需要针对特定网站进行优化，可以修改以下配置：

1. **登录元素选择器**: 修改 JavaScript 中的各种选择器数组
2. **等待条件**: 修改 `wait_for` 参数
3. **滑块处理**: 调整滑动步数和延迟
4. **登录检测**: 修改登录成功的判断条件
5. **表格提取**: 调整 `table_score_threshold` 值

## 注意事项

1. 确保网络连接正常
2. 首次运行时会下载浏览器驱动，需要一些时间
3. 滑块验证可能需要多次尝试
4. 不要在程序运行期间关闭浏览器窗口
5. 如果网站更新了登录界面，可能需要调整选择器
6. 建议在网络环境良好时运行程序

## 安全说明

- 用户名和密码直接写在代码中，请注意保护代码安全
- 建议使用测试账号进行调试
- 不要在生产环境中硬编码敏感信息
